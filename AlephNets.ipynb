{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería AlephNets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"./imagenes/logo_alephnets.png\" width = \"250px\">\n",
    "</center>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- **Autor@s:** A.T\n",
    "- **Licencia de Uso:** MIT.\n",
    "- **Email:** \n",
    "- **Google Site:** \n",
    "- **Linkedin:** link.com\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(dataset):\n",
    "    for element in dataset:\n",
    "        element.append(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clase Perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase Perceptrón.\n",
    "class Perceptron: \n",
    "  \n",
    "    # Método constructor.\n",
    "    def __init__(self, num_neurons, activation = \"sign\", criterion = \"perceptron_criterion\", learning_rate = 1):\n",
    "        if (criterion == \"hinge_loss\" or criterion == \"perceptron_criterion\" or criterion == \"widrow_hoff\") and activation != \"sign\": \n",
    "            raise Exception(criterion.replace(\"_\", \" \").capitalize() + \" can only be use with Sign activation function.\")\n",
    "        if (criterion == \"log_likelihood\" and activation != \"sigmoid\"):\n",
    "            raise Exception(criterion.replace(\"_\",\" \").capitalize() + \" can only be used with Sigmoid activation function\")\n",
    "        if (criterion == \"least_squares_regression\" and activation != \"linear\"):\n",
    "            raise Exception(criterion.replace(\"_\",\" \").capitalize() + \" can only be used with linear activation function\")\n",
    "   \n",
    "        self.num_neurons = num_neurons\n",
    "        self.activation = getattr(self, \"_\" + activation)\n",
    "        self.weights = np.random.rand(1, num_neurons)[0]\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = getattr(self, \"_\" + criterion)\n",
    "        self.loss_function = getattr(self, \"_\" + criterion + \"_loss\")\n",
    "        \n",
    "    # Forward method: computational step.\n",
    "    def forward(self, vector_x): \n",
    "        dotproduct = np.dot(vector_x, self.weights)\n",
    "        return self.activation(dotproduct)\n",
    "        \n",
    "    \"\"\"\n",
    "    Funciones de activación.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sign activation.\n",
    "    def _sign(self, x): \n",
    "        return np.sign(x)\n",
    "    \n",
    "    # Linear activation.\n",
    "    def _linear(self, x):\n",
    "        return x\n",
    "\n",
    "    # Sigmoid activation.\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "  \n",
    "    # Tanh activation.\n",
    "    def _tanh(self, x):\n",
    "        return 2 * self.sigmoid(2*x)-1\n",
    "\n",
    "    # Relu activation.\n",
    "    def _relu(self, x): \n",
    "        return max(0, x)\n",
    "  \n",
    "    # HardTanh activation.\n",
    "    def _hardTanh(self, x):\n",
    "        return max(min(x, 1), -1) \n",
    "    \n",
    "    \"\"\"\n",
    "    Error functions.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def _perceptron_criterion_loss(self,y_true,y_predicted):\n",
    "        loss = max(0,-y_true*y_predicted)\n",
    "        return loss\n",
    "    \n",
    "    def _logistic_regression_loss(self,y_true,y_predicted):\n",
    "        loss = -math.log(math.abs(y_true*(1/2)-0.5+y_predicted))\n",
    "        return loss\n",
    "    \n",
    "    def _hinge_loss_loss(self,y_true,y_predicted):\n",
    "        loss = max(0,-y_true*y_predicted+1)\n",
    "        return loss\n",
    "    \n",
    "    def _least_squares_regression_loss(self,y_true,y_predicted):\n",
    "        loss = (y_true-y_predicted)**2\n",
    "        return loss\n",
    "    \n",
    "    def _widrow_hoff_loss(self,y_true,y_predicted):\n",
    "        loss = (y_true-y_predicted)**2\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Gradient update functions.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Perceptron criterion.\n",
    "    def _perceptron_criterion(self, y_true, y_predicted, vector_x): \n",
    "        gradient = np.dot((y_true - y_predicted), vector_x)\n",
    "        return gradient\n",
    "  \n",
    "    # 2. Hinge Loss.\n",
    "    def _hinge_loss(self, y_true, y_predicted, vector_x): \n",
    "        if y_true != y_predicted:\n",
    "            gradient = np.dot(y_true, vector_x)\n",
    "            return gradient\n",
    "        return 0\n",
    "    \n",
    "    #3. Log likelihood.\n",
    "    def _log_likelihood(self, y_true, y_predicted, vector_x):\n",
    "        gradient = -(y_true*vector_x)/(1+math.exp(y_true*y_predicted))\n",
    "        return gradient\n",
    "    \n",
    "    #4. Least squares.\n",
    "    def _least_squares_regression(self, y_true, y_predicted, vector_x): \n",
    "        gradient = np.dot((y_true - y_predicted), vector_x)\n",
    "        return gradient\n",
    "    \n",
    "    #4. Least squares.\n",
    "    def _widrow_hoff_regression(self, y_true, y_predicted, vector_x): \n",
    "        gradient = np.dot((y_true - y_predicted), vector_x)\n",
    "        return gradient\n",
    "    \n",
    "    \"\"\"\n",
    "    Train and predict methods.\n",
    "    \"\"\"\n",
    "    # Train the perceptron.\n",
    "    def fit(self, X, Y, max_iterations = 100): \n",
    "\n",
    "        # Stochastic Gradient Descent.\n",
    "        for i in range(max_iterations):\n",
    "     \n",
    "            # Select random point.\n",
    "            randomPoint = random.randint(0, len(X) - 1)\n",
    "            vector_x = X[randomPoint].copy()\n",
    "\n",
    "            # Predict point category.\n",
    "            y_predicted = self.forward(vector_x)\n",
    "            y_true = Y[randomPoint]\n",
    "\n",
    "            # Compute gradient.\n",
    "            gradient = self.criterion(y_true, y_predicted, vector_x)\n",
    "\n",
    "            # Update weights.\n",
    "            self.weights = self.weights + self.learning_rate * gradient\n",
    "            \n",
    "    # Predict value/category.\n",
    "    def predictValue(self, x): \n",
    "        y_predicted = self.forward(x)\n",
    "        return y_predicted\n",
    "\n",
    "    # Predict list.\n",
    "    def predictList(self, X, Y, show_results = False): \n",
    "\n",
    "        error_criterion = np.zeros(len(self.weights))\n",
    "        accuracy = 0\n",
    "\n",
    "        for i in range(0, len(X)):\n",
    "\n",
    "            vector_x = X[i].copy()\n",
    "            \n",
    "            y_true = Y[i]\n",
    "            y_predicted = self.predictValue(vector_x)\n",
    "            error = self.loss_function(y_true, y_predicted)\n",
    "            correct = (y_true == y_predicted)\n",
    "\n",
    "            if show_results: \n",
    "                print(\"Point: \", vector_x)\n",
    "                print(\"True Label: \", y_true)\n",
    "                print(\"Prediction: \", y_predicted)\n",
    "                print(\"Error: \", error)\n",
    "                print(\"\")\n",
    "\n",
    "            error_criterion += error\n",
    "            if correct: \n",
    "                accuracy += 1\n",
    "\n",
    "        print(\"Criterion Error: \", error_criterion)\n",
    "        print(\"Accuracy: \", accuracy / len(X))    \n",
    "       \n",
    "    # Get weights.\n",
    "    def getWeights(self): \n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
